{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score, mean_squared_error,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../../dataset/fakenews_dataset/300dims_vectorized_spacy44k.json','r')\n",
    "data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[]\n",
    "X=[]\n",
    "X1=[]\n",
    "X2=[]\n",
    "X3=[]\n",
    "Y=[]\n",
    "ID=[]\n",
    "for x in data:\n",
    "    ID.append(x)\n",
    "    if(len(data[x])!=4):\n",
    "        print(x)\n",
    "    Y.append(data[x][0])\n",
    "    X1.append([data[x][1]])\n",
    "    X2.append(data[x][2])\n",
    "    X3.append(data[x][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44171, 1)\n",
      "(44171, 300)\n",
      "(44171, 300)\n",
      "(44171, 601)\n"
     ]
    }
   ],
   "source": [
    "X1=(np.array(X1))\n",
    "X2=np.array(X2)\n",
    "X3=np.array(X3)\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "print(X3.shape)\n",
    "X=np.concatenate((X1,X2,X3),axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put ratio here\n",
    "test_size = 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=0)\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.975930491957262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nannu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "saved_model = joblib.load('lr300_44k_w.pkl')\n",
    "print(\"F1: \",f1_score(Y_test, saved_model.predict(X_test_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44171, 1)\n",
      "(44171, 300)\n",
      "(44171, 300)\n",
      "(44171, 600)\n"
     ]
    }
   ],
   "source": [
    "X1=(np.array(X1))\n",
    "X2=np.array(X2)\n",
    "X3=np.array(X3)\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "print(X3.shape)\n",
    "Xh=np.concatenate((X2,X3),axis=1)\n",
    "print(Xh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put ratio here\n",
    "test_size = 0.2\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(Xh, Y, test_size=test_size, random_state=0)\n",
    "sc = StandardScaler()\n",
    "X_train_std1 = sc.fit_transform(X_train1)\n",
    "X_test_std1 = sc.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.9761653164259717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nannu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.24.2 when using version 1.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "saved_model = joblib.load('lr300_44k_wo.pkl')\n",
    "print(\"F1: \",f1_score(Y_test1, saved_model.predict(X_test_std1)))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c06c732e4d2a83802a2e708a53cf15ef57dc40d97efa09876204595301950dd0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
